// mergeResults.js com AlaSQL e caminhos originais

import alasql from "alasql"; // Importa o AlaSQL
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import getBrasiliaTime from "./getBrasiliaTime.js";

// Configura√ß√µes de caminho (mantidas conforme sua especifica√ß√£o)
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Definindo vari√°veis de caminho configur√°veis
const DEFAULT_OLD_RESULTS_PATH = path.join(
  __dirname,
  "../../querocasa/data/results"
);
const DEFAULT_NEW_RESULTS_PATH = path.join(__dirname, "../../data/results");

// Vari√°veis que podem ser modificadas pela fun√ß√£o configurePaths
let OLD_RESULTS_PATH = DEFAULT_OLD_RESULTS_PATH;
let NEW_RESULTS_PATH = DEFAULT_NEW_RESULTS_PATH;

const PLATFORMS = ["olx", "zap"];
const MAX_CONSECUTIVE_MISSES = 3; // N√∫mero de scrapes que um item pode faltar
const MAX_DAYS_TO_KEEP_REMOVED = 5; // N√∫mero de dias para manter itens removidos

/**
 * Fun√ß√£o para configurar caminhos alternativos - usada principalmente para testes e CI
 */
export function configurePaths(oldPath, newPath) {
  OLD_RESULTS_PATH = oldPath || DEFAULT_OLD_RESULTS_PATH;
  NEW_RESULTS_PATH = newPath || DEFAULT_NEW_RESULTS_PATH;
  console.log(
    `[configurePaths] Caminhos configurados: OLD=${OLD_RESULTS_PATH}, NEW=${NEW_RESULTS_PATH}`
  );
}

/**
 * Fun√ß√£o para leitura segura de arquivos JSON
 */
async function safeReadJsonFile(filePath) {
  try {
    if (!fs.existsSync(filePath)) {
      console.warn(`[safeRead] Arquivo n√£o encontrado: ${filePath}`);
      return [];
    }
    const fileContent = await fs.promises.readFile(filePath, "utf8");
    if (!fileContent.trim()) {
      console.warn(`[safeRead] Arquivo vazio: ${filePath}`);
      return [];
    }
    const parsedData = JSON.parse(fileContent);
    if (!Array.isArray(parsedData)) {
      console.warn(
        `[safeRead] Conte√∫do inv√°lido (n√£o √© array) em: ${filePath}`
      );
      return [];
    }
    return parsedData;
  } catch (error) {
    console.error(
      `[safeRead] Erro ao ler/parsear arquivo ${filePath}:`,
      error.message
    );
    return [];
  }
}

/**
 * Verifica e cria a estrutura de diret√≥rios e arquivos necess√°rios (OPCIONAL)
 * Se seus arquivos j√° s√£o garantidos pela pipeline, pode n√£o ser necess√°rio.
 * Mantido para consist√™ncia com seu script original.
 */
async function checkAndCreateResultsDirectory() {
  try {
    if (!fs.existsSync(OLD_RESULTS_PATH)) {
      await fs.promises.mkdir(OLD_RESULTS_PATH, { recursive: true });
      console.log(`Diret√≥rio antigo criado: ${OLD_RESULTS_PATH}`);
    }
    if (!fs.existsSync(NEW_RESULTS_PATH)) {
      await fs.promises.mkdir(NEW_RESULTS_PATH, { recursive: true });
      console.log(`Diret√≥rio de novos dados criado: ${NEW_RESULTS_PATH}`);
    }

    for (const platform of PLATFORMS) {
      const existingFilePath = path.join(
        OLD_RESULTS_PATH,
        `${platform}Results.json`
      );
      const newFilePath = path.join(
        NEW_RESULTS_PATH,
        `${platform}Results.json`
      );

      if (!fs.existsSync(existingFilePath)) {
        await fs.promises.writeFile(
          existingFilePath,
          JSON.stringify([], null, 2)
        );
        console.log(
          `Arquivo existente de fallback criado: ${existingFilePath}`
        );
      }
      if (!fs.existsSync(newFilePath)) {
        await fs.promises.writeFile(newFilePath, JSON.stringify([], null, 2));
        console.log(`Arquivo novo de fallback criado: ${newFilePath}`);
      }
    }
  } catch (error) {
    console.error("Erro ao verificar/criar diret√≥rios/arquivos:", error);
    // N√£o relan√ßar o erro aqui pode ser perigoso se os caminhos forem cr√≠ticos.
    // Se os diret√≥rios s√£o essenciais, talvez devesse relan√ßar.
  }
}

/**
 * Gera um ID √∫nico para novas propriedades
 */
function generateId() {
  return `prop_${Date.now()}_${Math.floor(Math.random() * 10000)}`;
}

/**
 * Processa os resultados de uma plataforma usando AlaSQL
 */
export const processPlatformResults = async (platform) => {
  const now = getBrasiliaTime();

  const oldFilePath = path.join(OLD_RESULTS_PATH, `${platform}Results.json`);
  const newDataFromScraperPath = path.join(
    NEW_RESULTS_PATH,
    `${platform}Results.json`
  );

  console.log(`\n[${platform}] üîÑ Processando resultados com AlaSQL...`);
  console.log(
    `[${platform}] üìÇ Carregando dados antigos de: ${path.resolve(oldFilePath)}`
  );
  let oldData = await safeReadJsonFile(oldFilePath);
  console.log(
    `[${platform}] üìÇ Carregando novos dados do scraper de: ${path.resolve(
      newDataFromScraperPath
    )}`
  );
  let newData = await safeReadJsonFile(newDataFromScraperPath);

  console.log(`[${platform}] üìä Itens antigos carregados: ${oldData.length}`);
  console.log(`[${platform}] üìä Itens novos do scraper: ${newData.length}`);

  let stats = {
    added: 0,
    updated: 0,
    removed: 0,
    reactivated: 0,
    stillMissing: 0,
    preservedUnlinked: 0,
  };

  // Pr√©-processamento para adicionar um campo virtual 'identifier' que ser√° usado para matching
  // Este campo usa o link original OU o primeiro link de imagem como fallback
  oldData = oldData.map((p, idx) => {
    const identifier =
      p.link || (p.images && p.images.length > 0 ? p.images[0] : null);
    return {
      ...p,
      platform: p.platform || platform,
      consecutiveMisses: p.consecutiveMisses || 0,
      tempId: `old_${idx}`,
      identifier,
    };
  });

  newData = newData.map((p, idx) => {
    const identifier =
      p.link || (p.images && p.images.length > 0 ? p.images[0] : null);
    return {
      ...p,
      platform: p.platform || platform,
      tempId: `new_${idx}`,
      identifier,
    };
  });

  // Separar itens com e sem identificador para tratamento diferenciado
  const oldUnlinkedItems = alasql("SELECT * FROM ? WHERE identifier IS NULL", [
    oldData,
  ]);
  const oldLinkedItems = alasql(
    "SELECT * FROM ? WHERE identifier IS NOT NULL",
    [oldData]
  );
  const newUnlinkedItems = alasql("SELECT * FROM ? WHERE identifier IS NULL", [
    newData,
  ]);
  const newLinkedItems = alasql(
    "SELECT * FROM ? WHERE identifier IS NOT NULL",
    [newData]
  );

  let mergedData = [
    ...oldUnlinkedItems.map((p) => {
      delete p.tempId;
      return p;
    }),
  ]; // Come√ßa com os antigos sem link
  stats.preservedUnlinked = oldUnlinkedItems.length;

  newUnlinkedItems.forEach((newProp) => {
    stats.added++;
    const { tempId, ...finalProp } = newProp; // Remove tempId
    mergedData.push({
      ...finalProp,
      id: finalProp.id || generateId(),
      firstSeenAt: now,
      lastSeenAt: now,
      scrapedAt: finalProp.scrapedAt || now,
      __status: "added",
      consecutiveMisses: 0,
    });
  });

  // Caso 1: Scraper n√£o retornou NADA COM IDENTIFICADOR, mas t√≠nhamos dados antigos COM IDENTIFICADOR.
  if (newLinkedItems.length === 0 && oldLinkedItems.length > 0) {
    console.warn(
      `[${platform}] Nenhum dado novo COM IDENTIFICADOR do scraper. Verificando antigos COM IDENTIFICADOR para remo√ß√£o por aus√™ncia.`
    );
    const updatedOldLinked = oldLinkedItems.map((oldProp) => {
      const misses = oldProp.consecutiveMisses + 1;
      let newStatus = oldProp.__status;
      if (oldProp.__status !== "removed" && misses >= MAX_CONSECUTIVE_MISSES) {
        newStatus = "removed";
        stats.removed++;
      } else if (oldProp.__status !== "removed") {
        stats.stillMissing++;
      }
      const { tempId, ...finalProp } = oldProp;
      return {
        ...finalProp,
        __status: newStatus,
        consecutiveMisses: misses,
        lastSeenAt: oldProp.lastSeenAt,
      }; // Mant√©m lastSeenAt anterior
    });
    mergedData.push(...updatedOldLinked);
  } else if (newLinkedItems.length > 0 || oldLinkedItems.length > 0) {
    // Caso 2: Processamento normal para itens com link
    // Usamos SQL para fazer o JOIN e determinar o status inicial
    const sql = `
      SELECT 
        COALESCE(o.identifier, n.identifier) AS identifier,
        o.tempId AS old_tempId,
        n.tempId AS new_tempId,
        CASE
          WHEN o.identifier IS NULL THEN 'added'       -- S√≥ existe em new
          WHEN n.identifier IS NULL THEN 'missing'     -- S√≥ existe em old
          ELSE 'updated'                        -- Existe em ambos
        END AS merge_status
      FROM ? AS o FULL OUTER JOIN ? AS n ON o.identifier = n.identifier AND o.platform = n.platform
      WHERE o.platform = '${platform}' OR n.platform = '${platform}'`;

    const joinedResult = alasql(sql, [oldLinkedItems, newLinkedItems]);

    for (const item of joinedResult) {
      let finalItemData = {};
      let oldProp = null;
      let newProp = null;

      if (item.old_tempId)
        oldProp = oldLinkedItems.find((p) => p.tempId === item.old_tempId);
      if (item.new_tempId)
        newProp = newLinkedItems.find((p) => p.tempId === item.new_tempId);

      if (item.merge_status === "added") {
        stats.added++;
        const { tempId, ...relevantNewPropFields } = newProp;
        finalItemData = {
          ...relevantNewPropFields,
          id: newProp.id || generateId(),
          firstSeenAt: now,
          lastSeenAt: now,
          scrapedAt: newProp.scrapedAt || now,
          __status: "added",
          consecutiveMisses: 0,
        };
      } else if (item.merge_status === "updated") {
        if (oldProp.__status === "removed") stats.reactivated++;
        stats.updated++;
        const { tempId: oldTempId, ...relevantOldPropFields } = oldProp;
        const { tempId: newTempId, ...relevantNewPropFields } = newProp;
        finalItemData = {
          ...relevantOldPropFields,
          ...relevantNewPropFields, // newProp sobrescreve campos comuns
          id: oldProp.id || newProp.id || generateId(), // Preserva ID antigo se poss√≠vel
          firstSeenAt: oldProp.firstSeenAt || now,
          lastSeenAt: now,
          scrapedAt: oldProp.scrapedAt || newProp.scrapedAt || now, // Preserva scrapedAt original
          __status: "updated",
          consecutiveMisses: 0,
        };
      } else {
        // 'missing' - item estava em oldData, mas n√£o em newData
        const misses = oldProp.consecutiveMisses + 1;
        let currentStatus = oldProp.__status;

        if (currentStatus !== "removed" && misses >= MAX_CONSECUTIVE_MISSES) {
          currentStatus = "removed";
          stats.removed++;
          console.log(
            `[${platform}] Item ${oldProp.link} (ID: ${oldProp.id}) marcado como REMOVIDO ap√≥s ${misses} aus√™ncias.`
          );
        } else if (currentStatus !== "removed") {
          stats.stillMissing++;
          console.log(
            `[${platform}] Item ${oldProp.link} (ID: ${oldProp.id}) ausente (tentativa ${misses}/${MAX_CONSECUTIVE_MISSES}). Mantendo status anterior.`
          );
        }
        const { tempId, ...relevantOldPropFields } = oldProp;
        finalItemData = {
          ...relevantOldPropFields,
          __status: currentStatus,
          consecutiveMisses: misses,
          lastSeenAt: oldProp.lastSeenAt, // Mant√©m lastSeenAt da √∫ltima vez que foi visto
        };
      }
      // Adicionar todos os campos que voc√™ precisa explicitamente para garantir a estrutura
      const cleanItem = {
        id: finalItemData.id,
        link: finalItemData.link,
        platform: finalItemData.platform || platform, // Garante plataforma
        address: finalItemData.address,
        description: finalItemData.description || [], // Padr√µes
        images: finalItemData.images || [],
        price: finalItemData.price,
        scrapedAt: finalItemData.scrapedAt,
        publishDate: finalItemData.publishDate,
        firstSeenAt: finalItemData.firstSeenAt,
        lastSeenAt: finalItemData.lastSeenAt,
        hasDuplicates: finalItemData.hasDuplicates || false,
        coords: finalItemData.coords, // Pode precisar de tratamento se for objeto
        __status: finalItemData.__status,
        consecutiveMisses: finalItemData.consecutiveMisses,
        // ... quaisquer outros campos que seu objeto 'prop' original tinha
      };
      mergedData.push(cleanItem);
    }
  }

  let finalUniqueData = Array.from(
    new Map(
      mergedData.filter((p) => p && p.id).map((item) => [item.id, item])
    ).values()
  );

  console.log(
    `[${platform.toUpperCase()} Merge Stats (AlaSQL)] Adicionados: ${
      stats.added
    }, Atualizados: ${stats.updated}, Removidos: ${
      stats.removed
    }, Reativados: ${stats.reactivated}, Ainda Ausentes: ${
      stats.stillMissing
    }, Preserv. Sem Link: ${stats.preservedUnlinked}`
  );
  console.log(
    `[${platform.toUpperCase()}] Total de itens ap√≥s merge: ${
      finalUniqueData.length
    }`
  );

  const finalData = finalUniqueData.filter((item) => {
    if (item.__status !== "removed") return true;

    // Para itens removidos, verifica h√° quanto tempo foram vistos pela √∫ltima vez
    if (!item.lastSeenAt) return true; // Se n√£o tiver lastSeenAt, mant√©m por seguran√ßa

    const lastSeenDate = new Date(item.lastSeenAt);
    const currentDate = new Date(now);
    const diffTime = Math.abs(currentDate.getTime() - lastSeenDate.getTime());
    const diffDays = Math.ceil(diffTime / (1000 * 60 * 60 * 24));

    // Mant√©m apenas se o n√∫mero de dias for menor ou igual ao limite configurado (5 dias)
    const keepItem = diffDays <= MAX_DAYS_TO_KEEP_REMOVED;
    if (!keepItem) {
      console.log(
        `[${platform}] üßπ Removendo permanentemente item ${
          item.id || item.link || "sem ID"
        } - n√£o visto h√° ${diffDays} dias`
      );
    }
    return keepItem;
  });

  if (finalData.length < finalUniqueData.length) {
    console.log(
      `[${platform}] üßπ Limpeza: removidos ${
        finalUniqueData.length - finalData.length
      } itens antigos (ap√≥s ${MAX_DAYS_TO_KEEP_REMOVED} dias)`
    );
    // Atualiza o arquivo com os dados limpos
    await fs.promises.writeFile(
      oldFilePath,
      JSON.stringify(finalData, null, 2)
    );

    // Atualiza vari√°vel para refletir nos logs finais
    finalUniqueData = finalData;
  }

  // Atualizar GITHUB_ENV
  if (process.env.GITHUB_ENV) {
    const envPath = process.env.GITHUB_ENV;
    const platformUpper = platform.toUpperCase();
    fs.appendFileSync(envPath, `${platformUpper}_ADDED=${stats.added}\n`);
    fs.appendFileSync(envPath, `${platformUpper}_UPDATED=${stats.updated}\n`);
    fs.appendFileSync(envPath, `${platformUpper}_REMOVED=${stats.removed}\n`);
    fs.appendFileSync(
      envPath,
      `${platformUpper}_TOTAL=${finalUniqueData.length}\n`
    );
  }

  // Salvar os dados finais no arquivo
  await fs.promises.writeFile(
    oldFilePath,
    JSON.stringify(finalUniqueData, null, 2)
  );

  console.log(
    `[${platform}] ‚úÖ Dados salvos com sucesso: ${finalUniqueData.length} itens`
  );
};
